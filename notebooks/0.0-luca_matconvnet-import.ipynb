{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# global packages\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# local packages\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.convolutional import *\n",
    "from src.make_branch_alexnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# net to import\n",
    "net_path = '../pretrained/xc_conv5_32c_s4_e40.mat'\n",
    "# Layers that need to be imported from MatConvnet architecture\n",
    "conv_to_import = ['br1_conv1','br1_conv2','br1_conv3','br1_conv4','br1_conv5','br2_conv1','br2_conv2','br2_conv3','br2_conv4','br2_conv5']\n",
    "bnorm_to_import = ['br1_bn1','br1_bn2','br1_bn3','br1_bn4','br2_bn1','br2_bn2','br2_bn3','br2_bn4','fin_adjust_bn']\n",
    "layers_to_import = conv_to_import + bnorm_to_import\n",
    "\n",
    "# read mat file from path\n",
    "mat = scipy.io.loadmat(net_path)\n",
    "## This is for .mat files saved with --v7.3\n",
    "# import h5py\n",
    "# net_file = h5py.File(net_path, 'r')\n",
    "# data = f.get('...') \n",
    "net = mat.get('net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = net['layers']\n",
    "layers = layers[0][0]\n",
    "# all layer names\n",
    "layer_names = layers['name'][0]\n",
    "# copy the numpy.ndarray in a list\n",
    "layer_names_list = [layer_names[l][0] for l in xrange(layer_names.size)]\n",
    "# all param names organized by layers\n",
    "param_names = layers['params'][0]\n",
    "# param_names_list = [param_names[l][0] for l in xrange(param_names.size)]\n",
    "\n",
    "# verify that layers_to_import are all present in layer_names + find positions\n",
    "layers_to_import_pos = [layer_names_list.index(lname) for lname in layers_to_import]\n",
    "\n",
    "#TODO: raise error if in mat file there are layers with learnt parameters not present in layers_to_import\n",
    "\n",
    "# create a dictionary to map layer -> params (<key,value> = <string,list> )\n",
    "layer_to_params = {}\n",
    "for i in xrange(len(layers_to_import_pos)):    \n",
    "    l_param_names = param_names[layers_to_import_pos[i]][0]\n",
    "    l_param_names_list = [l_param_names[p][0] for p in xrange(l_param_names.size)]\n",
    "    layer_to_params[layer_names_list[layers_to_import_pos[i]]] = l_param_names_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# organize parameters to import\n",
    "params = net['params']\n",
    "params = params[0][0]\n",
    "params_names = params['name'][0]\n",
    "params_names_list = [params_names[p][0] for p in xrange(params_names.size)]\n",
    "params_values = params['value'][0]\n",
    "params_values_list = [params_values[p] for p in xrange(params_values.size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# layers_to_import -> layers_to_params -> params_names_list -> params_values_list\n",
    "\n",
    "# e.g:\n",
    "conv1f = params_values_list[params_names_list.index('br_conv1f')]\n",
    "conv1b = params_values_list[params_names_list.index('br_conv1b')]\n",
    "X = tf.placeholder(tf.float32)\n",
    "X1 = tf.expand_dims(X, 0)\n",
    "#TODO: function convolutional does not know tf\n",
    "#h1 = set_convolutional(X1, conv1f, conv1b, 11, 11, 3, 96, stride=2, scope='conv1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# root_path = '/media/berti/STORAGE1/ILSVRC2015_crops/Data/VID/train'\n",
    "# video_path = 'b/ILSVRC2015_train_00234012'\n",
    "# crop = '000019.01.crop.z.jpg'\n",
    "# im = plt.imread(path.join(root_path, video_path, crop))\n",
    "# print im.shape\n",
    "# plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.initialize_all_variables())\n",
    "#     out = sess.run(h1, feed_dict={X: im})\n",
    "\n",
    "# print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tf.InteractiveSession()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
